# üìò Documentation du module goblin-agents

## Aper√ßu

Le module `goblin-agents` fournit une infrastructure compl√®te pour int√©grer des agents d'intelligence artificielle (IA) dans l'√©cosyst√®me Xcraft. Il permet de cr√©er, configurer et interagir avec diff√©rents mod√®les de langage (LLM) via des fournisseurs comme Ollama et OpenAI. Ce module est con√ßu pour faciliter l'utilisation d'agents IA dans diverses applications, en offrant des fonctionnalit√©s avanc√©es comme la gestion de conversations, l'analyse de documents PDF, et l'utilisation d'outils externes.

## Structure du module

- **AiAgent** : Acteur principal qui encapsule un agent IA et ses fonctionnalit√©s
- **Providers** : Classes pour interagir avec diff√©rents fournisseurs de LLM (Ollama, OpenAI)
- **Utilitaires** : Fonctions pour le traitement de texte, l'OCR, et la manipulation de documents

Le module est organis√© autour du pattern Elf, avec une s√©paration claire entre la logique m√©tier (`AiAgentLogic`) et l'interface de l'acteur (`AiAgent`).

## Fonctionnement global

Le module `goblin-agents` permet de cr√©er et g√©rer des agents IA qui peuvent interagir avec les utilisateurs via des conversations textuelles. Chaque agent est configur√© avec un mod√®le sp√©cifique, un fournisseur (Ollama ou OpenAI), et des param√®tres qui d√©finissent son comportement.

Les agents peuvent maintenir plusieurs contextes de conversation simultan√©ment, ce qui permet d'avoir des conversations distinctes avec diff√©rents utilisateurs ou sur diff√©rents sujets. Chaque contexte conserve son propre historique de messages, ce qui permet √† l'agent de maintenir la coh√©rence dans ses r√©ponses.

Le module prend en charge diverses fonctionnalit√©s avanc√©es :
- G√©n√©ration de texte √† partir de prompts
- Conversations interactives avec historique
- Extraction de texte √† partir d'images de documents PDF
- G√©n√©ration d'embeddings vectoriels pour la recherche s√©mantique
- Utilisation d'outils externes via un syst√®me d'appels d'outils
- Paradigme ReAct (Reasoning and Acting) pour des agents plus autonomes

Les agents peuvent √™tre configur√©s avec une grande vari√©t√© d'options qui influencent leur comportement, comme la temp√©rature (cr√©ativit√©), la taille du contexte, et diverses p√©nalit√©s pour √©viter les r√©p√©titions.

## Exemples d'utilisation

### Cr√©ation d'un agent IA

```javascript
const {AiAgent} = require('goblin-agents/lib/llm/aiAgent.js');

// Dans une m√©thode d'un acteur Elf
async initAgents() {  
  const feedId = await this.newQuestFeed();

  // Cr√©ation d'un agent avec Ollama (local)
  const ollamaAgentId = SmartId.from('aiAgent', 'ollama-mistral-assistant');
  const agent = await new AiAgent(this).create(ollamaAgentId, feedId, {
    name: 'Assistant Personnel',
    role: 'assistant',
    prompt: 'Tu es un assistant personnel serviable et pr√©cis.',
    provider: 'ollama',
    model: 'mistral-small',
    host: 'http://127.0.0.1:11434',
    options: {
      temperature: 0.7
    },
    usability: 'stable'
  });

  // Cr√©ation d'un agent avec OpenAI (cloud)
  const openAiAgentId = SmartId.from('aiAgent', 'gpt-4o-assistant');
  const agent = await new AiAgent(this).create(openAiAgentId, feedId, {
    name: 'Assistant Personnel',
    role: 'assistant',
    provider: 'open-ai',
    model: 'openai/gpt-4o',
    host: 'https://openrouter.ai/api/v1',
    headers: {
      Authorization: `Bearer <votre-clef-api>`,
    },
    usability: 'stable'
  });
```

### Conversation avec un agent

```javascript

// Dans une m√©thode d'un acteur Elf
async askAgent(desktopId, agentId, contextId, question, saveExchange = false) {
  const feedId = await this.newQuestFeed();
  
  // Instancie l'agent appropri√© par ex. 'aiAgent@gpt-4o-assistant'
  const agent = await new AiAgent(this).create(agentId, feedId);
 
  // Continue la conversation sur ce contexte par ex. 'story-xyz' et 
  // obtient une r√©ponse √† la question de l'utilisateur
  const response = await agent.chat(contextId, question, desktopId);

  if(saveExchange) {
    //Persiste l'√©change contextuel nouvelle paire (question->r√©ponse) sur le disque
    await agent.save();
  }
  return response;
}
```

### R√©sumer et "squasher" un contexte

```javascript

// Dans une m√©thode d'un acteur Elf
async resumeAndSquashContexte(agentId, contextId) {
  const feedId = await this.newQuestFeed();
  
  // Instancie l'agent appropri√© par ex. 'aiAgent@gpt-4o-assistant'
  const agent = await new AiAgent(this).create(agentId, feedId);

  // Demande un r√©sum√© des √©changes
  const resumePrompt = "R√©sume l'essentiel de nos √©changes en utilisant l'historique des messages";
  const resumedContent = await agent.resumeExchange(resumePrompt, contextId);

  // Reset la m√©moire contextuel et persiste le changement
  await agent.reset(contextId, true);

  // Ajoute un nouvel historique d'√©change a partir du r√©sum√© 
  await agent.set(contextId, [{role: 'assistant', content: resumedContent}]);

  // Sauve ce nouvel √©tat
  await agent.save();
}
```

### Utilisation d'outils externes

```javascript

// Dans une m√©thode d'un acteur Elf
async addWeatherToolSupportToAgent(agentId) {
  const feedId = await this.newQuestFeed();
  
  // Instancie l'agent appropri√© par ex. 'aiAgent@gpt-4o-assistant'
  const agent = await new AiAgent(this).create(agentId, feedId);

  // Configurer un agent avec des outils
  // Provoquera des envois de commandes sur le bus √† l'acteur "weather"
  // en appelant la qu√™te "getWeather(city)"
  await agent.patch({
    toolServiceId: 'weather', //acteur (ici le singleton weather) qui expose des qu√™tes "outils"
    tools: [
      {
        type: 'function',
        function: {
          name: 'getWeather', //nom de la qu√™te de l'acteur qui r√©cup√®re la m√©t√©o
          description: 'Obtenir la m√©t√©o pour une ville',
          parameters: {
            type: 'object',
            properties: {
              city: {
                type: 'string',
                description: 'Nom de la ville'
              }
            },
            required: ['city']
          }
        }
      }
    ]
  });
}


// L'agent pourra maintenant utiliser l'outil weather.getWeather
const question = "Quel temps fait-il √† Paris aujourd'hui?";
const response = await agent.chat(contextId, question, desktopId);

```

### G√©n√©ration d'embeddings pour la recherche s√©mantique

```javascript

// Dans une m√©thode d'un acteur Elf
// {
//  'indexContent@article-1', 'Contenu √† indexer'
//  'indexContent@article-2', 'Un autre contenu √† indexer'
// }
//
async updateKnowledgeBase(articles) {
  const feedId = await this.newQuestFeed();

  // Instancie l'agent appropri√© pour faire un embedding
  // par ex. 'aiAgent@default-embedder'
  const agent = await new AiAgent(this).create(agentId, feedId);

  // R√©cup√®re les textes √† indexer
  const texts = Object.values(articles);

  // Pr√©pare un boucle d'insertion par id d'article
  const articlesIds = Object.keys(articles);

  // G√©n√©rer des embeddings pour plusieurs textes en une seule requ√™te
  const vectorsBatch = await agent.embedInBatch(texts);

  // Upsert les articles dans un archetype IndexedContent 
  for(const articleId of articleIds) {
    // R√©cup√®re les vecteurs correspondant au texte dans le lot 
    // et le texte original
    const index = articleIds.indexOf(articleId);
    const vectors = vectorsBatch[index];
    const text = texts[index];

    const indexedContent = new IndexedContentState({
      id: articleId,
      text, //texte original de l'article
      meta: {
        locale: 'fr', //d√©finit la locale
        scope: 'knowledge-base', //d√©finit le scope
        vectors, //vecteur correspondants au texte
        status: 'published',
      }
    });

    // Effectue l'upsert de l'archetype
    await new IndexedContent(this).insertOrReplace(
      articleId,
      feedId,
      indexedContent
    );
  }
}

// Dans une m√©thode d'un acteur Elf
async queryKnowledgeBase(question = "Comment fonctionne l'apprentissage par renforcement?") {
  const feedId = await this.newQuestFeed();

  // Instancie l'agent appropri√© pour faire un embedding
  // par ex. 'aiAgent@default-embedder'
  const agent = await new AiAgent(this).create(agentId, feedId);

  // G√©n√©rer un embedding pour un texte, par ex. pour une recherche
  // Convertit la question texte en vecteurs
  const vectors = await agent.embed(question);

  // Effectue une recherche par similitude dans cryo
  // Utilise un Archetype "IndexedContent"
  // Limite la recherche au contenu index√© en fran√ßais
  // avec un scope 'knowledge-base'
  // les 100 premier r√©sultats les plus pertinents
  const results = await this.cryo.searchDistance2(
    IndexedContentLogic.db,
    vectors,
    ['fr'],
    ['knowledge-base'],
    100
  );

  // It√®re sur les donn√©es et retourne les r√©sultats
  // a l'appelant
  return Array.from(results);
}
```

## Interactions avec d'autres modules

Le module `goblin-agents` interagit avec plusieurs autres composants de l'√©cosyst√®me Xcraft :

- **xcraft-core-goblin** : Fournit l'infrastructure Elf pour la cr√©ation d'acteurs
- **xcraft-core-stones** : Utilis√© pour la d√©finition des types de donn√©es
- **xcraft-core-utils** : Utilis√© pour les appels API REST et la gestion des verrous

Le module peut √©galement interagir avec d'autres services Goblin via le syst√®me d'appels d'outils, permettant aux agents d'effectuer des actions concr√®tes dans l'application.

## Configuration avanc√©e

- **version** : Version des agents (par d√©faut: 2)
- **defaultProfile** : Profil par d√©faut des agents (par d√©faut: null)
- **defaultSettings** : Param√®tres par d√©faut (par d√©faut: null)
- **profiles** : Profils pour remplacer les param√®tres (par d√©faut: {})
- **settings** : Param√®tres par nom (par d√©faut: {})

## D√©tails des sources

### `aiAgent.js`

Ce fichier est le point d'entr√©e du module, exportant les commandes Xcraft pour l'acteur AiAgent. Il importe l'acteur et sa logique depuis le fichier principal et les expose au syst√®me Xcraft.

### `config.js`

Ce fichier d√©finit la configuration du module, permettant de sp√©cifier :

- Le profil par d√©faut des agents (`defaultProfile`)
- Les param√®tres par d√©faut (`defaultSettings`)
- Les profils pour remplacer les param√®tres (`profiles`)
- Les param√®tres par nom (`settings`)

Cette configuration permet de personnaliser le comportement des agents au niveau de l'application.

### `lib/llm/aiAgent.js`

Ce fichier contient la d√©finition compl√®te de l'acteur AiAgent, avec :

- **MessageShape** : D√©finit la structure des messages √©chang√©s (r√¥le, contenu, images, appels d'outils)
- **OptionsShape** : D√©finit les nombreuses options de configuration des mod√®les LLM
- **AiAgentShape** : D√©finit la structure des donn√©es de l'agent
- **AiAgentState** : Classe d'√©tat de l'agent bas√©e sur le shape
- **AiAgentLogic** : Logique m√©tier de l'agent (mutations d'√©tat)
- **AiAgent** : Classe principale de l'acteur avec les m√©thodes d'interaction

L'acteur AiAgent offre de nombreuses m√©thodes pour interagir avec les mod√®les de langage, g√©rer les conversations, et utiliser des outils externes. Il prend en charge diff√©rentes configurations et options pour personnaliser le comportement des mod√®les.

Les options de configuration sont particuli√®rement riches et permettent d'ajuster finement le comportement des mod√®les, notamment :
- Gestion de la m√©moire (NUMA, VRAM)
- Taille du contexte et traitement par lots
- Param√®tres de g√©n√©ration (temp√©rature, top_k, top_p)
- P√©nalit√©s pour √©viter les r√©p√©titions
- Algorithmes adaptatifs comme Mirostat

### `lib/llm/providers.js`

Ce fichier d√©finit les classes pour interagir avec diff√©rents fournisseurs de LLM :

- **LLMProvider** : Classe abstraite d√©finissant l'interface commune
- **OllamaProvider** : Impl√©mentation pour le fournisseur Ollama (local)
- **OpenAIProvider** : Impl√©mentation pour OpenAI et services compatibles

Ces classes encapsulent les d√©tails d'impl√©mentation sp√©cifiques √† chaque fournisseur, offrant une interface unifi√©e pour le reste du module. Elles g√®rent les diff√©rences dans les formats de requ√™te et de r√©ponse, permettant √† l'acteur AiAgent de fonctionner de mani√®re transparente avec diff√©rents fournisseurs.

### `lib/llm/utils.js`

Ce fichier contient diverses fonctions utilitaires pour :

- Extraction de texte √† partir d'images PDF (`getPDFImages`)
- Nettoyage et simplification de contenu HTML (`cleanHtmlContent`, `simplifyHtml`)
- D√©coupage de texte en segments g√©rables (`splitLongText`, `html2chunks`)
- Estimation du nombre de tokens (`estimateTokenCount`)
- Construction de prompts √† partir d'articles (`buildPromptFromArticles`)
- Traitement par lots des embeddings (`embedChunksInBatch`, `chunkArray`)

Ces utilitaires sont essentiels pour pr√©parer les donn√©es avant de les envoyer aux mod√®les de langage et pour traiter les r√©sultats. Ils permettent notamment de g√©rer les contraintes de taille de contexte des mod√®les en d√©coupant intelligemment les textes longs.

Le module inclut √©galement des fonctionnalit√©s sp√©cifiques pour l'OCR (reconnaissance optique de caract√®res) avec un prompt syst√®me d√©di√© (`OCR_SYSTEM_PROMPT`) qui guide les mod√®les multimodaux dans l'extraction de texte √† partir d'images.

*Ce document est une mise √† jour de la documentation pr√©c√©dente.*